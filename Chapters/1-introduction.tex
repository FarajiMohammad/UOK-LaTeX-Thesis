\pagenumbering{arabic}
\twocolumnfootnotes
\titleformat{\chapter}[display]
{\normalfont\Large\BNazboldEGT\centering}
{\vspace*{8cm}{‎\textbf{فصل اول}}}{5pt}{\Large}
\chapter{ \textbf{مقدمه}  }\label{sec1}
\thispagestyle{empty}
\newpage

%%%%%%%%%%%%%%%%%
\section{بیان و اهمیت مسئله}
به دلیل تأثیرات منفی ویژگی‌های با ابعاد بالا\LTRfootnote{High dimentionality features}مانند افزایش پیچیدگی  یادگیری\LTRfootnote{Learning complexity}
\cite{liu2018onlinee,li2017granular}، افزایش تخصیص فضا\LTRfootnote{Heightened space allocation}
\cite{lin2017streaming}
و کاهش کارایی طبقه‌بندها \LTRfootnote{Classification}، توجه به روش‌های انتخاب‌ویژگی\LTRfootnote{Feature selection}روز‌به‌روز بیشتر شده است \cite{gao2018class}. در طول سال‌های اخیر، انتخاب ویژگی به یکی از مسائل مهم تبدیل شده است که تنها با انتخاب ویژگی‌های مرتبط\LTRfootnote{Relevant}و حذف ویژگی‌های تکراری\LTRfootnote{Redundant}و نامربوط\LTRfootnote{Irrelevant}
\cite{huang2017joint,zhu2018multi}،
می‌توان تعداد ویژگی‌ها را کاهش و کارایی مدل را بهبود داد. انتخاب ویژگی در مسائل مختلفی مانند: سیستم‌های توصیه‌گر\LTRfootnote{Recommender systems}، حاشیه‌نویسی تصویر
و ویدئو \LTRfootnote{Video annotation}\cite{hong2013image}، پردازش داده‌های ریزآرایه\LTRfootnote{Microarray data processing}و ژنومیکس\LTRfootnote{Genomics}\cite{xie2021unsupervised} به تدریج درحال گسترش است. از آنجایی که اشیاء در دنیای واقعی در عین حال چندین برچسب\LTRfootnote{Multi-Label}دارند، تحقیقات قابل توجهی در مورد انتخاب ویژگی در این حوزه‌ها انجام شده است. برای مثال در ژنومیکس، یک ژن می‌تواند چندین وظیفه‌ مانند: فتوسنتز\LTRfootnote{Photosynthesis}، تجزیه پروتئین\LTRfootnote{Protein breakdown}و انتقال سیگنال\LTRfootnote{Signal transmission}  \cite{wang2008building} داشته باشد.‎\\
در تحلیل موسیقی\LTRfootnote{Music analysis}، یک قطعه موسیقی می‌تواند همزمان دارای چند احساس مختلف مانند غم، شادی و ترس باشد \cite{trohidis2008multi}. همچنین در دسته‌بندی اخبار یک خبر می‌تواند جزو دسته‌های مختلفی باشد. در یادگیری چندبرچسبه، برخلاف مسائل چندکلاسه\LTRfootnote{Multi-Class}، همبستگی بین برچسب‌ها درنظر گرفته می‌شود. به همین دلیل، علاوه بر فضای ابعاد، استخراج و استفاده از همبستگی برچسب‌ها این مسئله را به یک مسئله \lr{NP-hard} تبدیل کرده است. 

درحال حاضر روش‌های انتخاب ویژگی چندبرچسبه بر روی استخراج همبستگی\LTRfootnote{Extraction of correlation} برچسب-برچسب، وابستگی برچسب-ویژگی و همبستگی ویژگی-ویژگی کار می‌کنند. روش‌های انتخاب ویژگی چندبرچسبه به دو دسته انتقال مسئله\LTRfootnote{Problem transformation}و تطبیق الگوریتم\LTRfootnote{Algorithm adaption}تقسیم می‌شوند\cite{6471714}. در رویکرد اول، مسئله به داده تک‌برچسبه\LTRfootnote{Single-Lable}تبدیل می‌شود و با استفاده از الگوریتم‌های تک‌برچسبه، حل می‌شوند. در رویکرد دوم، محققان تعدادی مدل انطباق الگوریتم ارائه داده‌اند که به‌صورت مستقیم مسائل چندبرچسبه را حل می‌کنند \cite{zhang2022non,jian2016multi}. همبستگی‌های برچسب عمدتاً توسط روش‌های انطباق الگوریتم برای روند انتخاب ویژگی استخراج می‌شوند. 
روش‌های تطبیق الگوریتم نسبت به روش‌های انتقال مسئله، بهینه‌تر هستند زیرا در تبدیل مسئله همبستگی بین برچسب‌ها در‌نظر گرفته‌ نمی‌شود. روش تطبیق الگوریتم به سه رویکرد مرتبه‌اول\LTRfootnote{First-order}، مرتبه‌دوم\LTRfootnote{Second-order}و مرتبه‌بالا\LTRfootnote{High-order}تقسیم می‌شود. در رویکرد مرتبه‌اول همبستگی بین برچسب‌ها درنظر گرفته نمی‌شود و برچسب‌ها مستقل از یکدیگر متصور می‌شوند. در رویکرد مرتبه‌دوم همبستگی جفت برچسب درنظر گرفته می‌شود. در عمل، یک رتبه‌بندی بین برچسب‌های مرتبط و غیرمرتبط خواهیم داشت. در رویکرد مرتبه‌بالا، همبستگی بین یک زیرمجموعه یا کل مجموعه برچسب‌ها درنظر گرفته می‌شود. در یادگیری چندبرچسبه، همبستگی بین برچسب‌ها می‌توانند داده‌های مهمی را ارائه دهند، برای مثال: اگر برچسب‌های اسکیت‌بُرد و برف وجود داشته باشند، به احتمال زیاد برچسب ورزش‌های زمستانی نیز وجود خواهد داشت. به‌طور مشابه اگر برچسب‌های دریا و هوای‌آفتابی وجود داشته باشند، به احتمال زیاد برچسب برف وجود ندارد. از این رو استفاده از سطح‌های مختلف همبستگی برچسب‌ها موردتوجه بسیاری از محققان قرار گرفته است \cite{zhou2018brief}. با توجه به مطالب گفته شده، نویسندگان \cite{furnkranz2008multilabel,ji2008extracting,read2011classifier} به‌طور گسترده بر روی همبستگی  سراسری برچسب‌ها \LTRfootnote{Global correlation}تمرکز کرده‌اند. در واقع، بعضی از همبستگی‌های برچسب \cite{huang2012multi,weng2018multi} بر روی همبستگی محلی\LTRfootnote{Local correlation}برچسب‌ها تمرکز کرده‌اند، برای مثال: در فضای اینترنت، کلمه 

آمازون به فروشگاه اینترنتی آمازون اشاره دارد، درحالی‌که همین کلمه در فضای طبیعت به جنگل آمازون اشاره دارد. اخیراً همبستگی‌های سراسری و محلی برچسب‌ها موردتوجه پژوهشگران بسیاری قرار گرفته است، که اگر به‌طور همزمان از دو همبستگی سراسری و محلی برچسب استفاده شود عملکرد یا نتایج بسیار بهتر و تأثیرگذارتر است. با توجه به مطالب بیان شده، در این پایان‌نامه، انتخاب ویژگی چندبرچسبه با استفاده از همبستگی سراسری و محلی\LTRfootnote{Multi-Label Feature Selection with Global and Local Label Correlation}برچسب‌ها ارائه شده است. 
بررسی‌های انجام شده نشان ‌می‌دهد که استفاده از یک فضای نهان بجای ماتریس اصلی نتایج بسیار بهتری را خواهد داشت از این رو فضای برچسب‌ها به یک ماتریس نهان\LTRfootnote{Latent matrix}انتقال می‌یابد، در فضای نهان برچسب‌ها، اطلاعات زائد و تکراری ماتریس اصلی حذف می‌شوند و یک ساختار فشرده‌تر و مفید با یک همبستگی ضمنی\LTRfootnote{Implicit}بین برچسب‌ها بدست می‌آید. 
همچنین با انتقال ماتریس ویژگی\LTRfootnote{Feature matrix}به این ماتریس نهان به راحتی الگو‌های مشترک بین ویژگی‌های مشابه\LTRfootnote{Similar features}و برچسب‌های مشابه\LTRfootnote{Similar labels}مشخص ‌می‌شوند. در نهایت اطلاعات ویژگی و برچسب در یک فضای مشترک\LTRfootnote{Shared space}خواهند ‌بود. 
اگرچه می‌توان گفت که در این فضا همبستگی ضمنی بین برچسب‌ها وجود دارد، اما می‌تواند بهتر شود. به این‌منظور همبستگی‌های سراسری و محلی برچسب‌ها از ماتریس برچسب استخراج\LTRfootnote{Extract}شده، این کار سبب می‌شود که پیش‌بینی در برچسب‌های بسیار مرتبط، مشابه باشند. برای یافتن ویژگی‌های مرتبط، روش پیشنهادی شامل همبستگی‌های برچسب ضمنی و صریح\LTRfootnote{Explicit}است و موجب کاهش أثرات‌منفی اطلاعات برچسب می‌شود. همچنین به منظور حفظ سازگاری\LTRfootnote{Consistency}بین فضای اصلی ویژگی‌ها در فضای نهان از منظم‌ساز خمینه‌\LTRfootnote{Manifold regularization}استفاده می‌کنیم. در نهایت از نُرم $\ell_{2,1} $ به منظور انتخاب ویژگی‌های متمایز و بهبود تفسیرپذیری ماتریس ضرایب بهره می‌بریم. 
اهداف اصلی روش ارائه‌ شده به‌صورت زیر خلاصه می‌شود:

\begin{itemize}
	\item  انتخاب ویژگی‌های متمایز با استفاده از همبستگی سراسری و محلی برچسب‌ها.
	\item انتقال فضای ویژگی و فضای برچسب به یک فضای مشترک و کم‌بُعد\LTRfootnote{Low-dimension}جهت استخراج الگوهای بین ویژگی‌ها و برچسب‌ها.
	\item معرفی یک مدل مبتنی بر تجزیه ماتریس نامنفی\LTRfootnote{Nonnegative Matrix Factorization}که دارای خاصیت خوشه‌بندی\LTRfootnote{Clustring}و تفسیرپذیری\LTRfootnote{Interpretability}برای انتخاب ویژگی‌های بهینه می‌باشد.
	\item استفاده از منظم‌ساز گراف\LTRfootnote{Graph regularization}جهت حفظ سازگاری بین فضای اصلی و نهان\LTRfootnote{Latent structure}.
	\item استفاده از یک الگوریتم کمینه‌سازی\LTRfootnote{Optimization}مؤثر جهت بهینه‌سازی\LTRfootnote{Minimization}مدل پیشنهادی.
	
\end{itemize}



\section{ساختار پایا‌ن‌نامه}

این پایا‌ن‌نامه به فصل‌های زیر تقسیم شده ‌است. در فصل‌اول، مقدمه‌ای بر پایا‌ن‌نامه شامل تعریف مسئله، تاریخچه و اهمیت آن،‌ هدف از پژوهش، مفروضات و روش انجام پژوهش پرداخته شده است. در فصل‌دوم، توضیح مفاهیم بنیادی\LTRfootnote{Foundational concepts}و کارهای مرتبط در این زمینه بیان می‌شود. در فصل‌سوم، معرفی روش پیشنهادی مبتنی بر تجزیه ماتریس نامنفی \cite{lee1999learning} که دارای خصوصیات ذاتی خوشه‌بندی و تفسیرپذیری جهت انتخاب ویژگی‌های مهم می‌باشد. در فصل‌چهارم، شرایط آزمایش، مجموعه‌داده‌های مورد استفاده، معیارهای ارزیابی بیان شده و سپس نتایج آزمایش‌های روش پیشنهادی ارائه می‌شوند. در فصل‌پنجم، به جمع‌بندی کلی روش‌ ارائه شده در این پایا‌ن‌نامه پرداخته و پیشنهادهایی برای توسعه و بهبود مدل ارائه شده برای کارهای آتی، مطرح می‌‌گردد.